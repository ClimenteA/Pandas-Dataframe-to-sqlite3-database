{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os, sys, re, string\n",
    "import itertools\n",
    "\n",
    "# \"\"\"\n",
    "# This module can be used to add from a parent folder all the excel files to a sqlite3 database.\n",
    "# The class requires the database name and the path where you have the excel files.\n",
    "\n",
    "# Warning: If it founds an .csv file it will save to database only the first sheet!\n",
    "# Requires pandas module to be installed.\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "class Df2db:\n",
    "    \n",
    "    def __init__(self, dbname, root_path):\n",
    "        self.dbname = dbname\n",
    "        self.root_path = root_path    \n",
    "    \n",
    "    def connect_db(self):\n",
    "        #Connect to a db and if it not exists creates one with the name given\n",
    "        connection = sqlite3.connect(self.dbname)\n",
    "        cursor = connection.cursor()\n",
    "        return connection, cursor\n",
    "    \n",
    "    def close(self):\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        connection.commit()\n",
    "        connection.close()\n",
    "    \n",
    "    def norm_pctmarks(self, astring):\n",
    "        #Removing punctuation marks from the string, necessary for making compatible table names\n",
    "        punctuation_marks = list(str(string.punctuation).replace('_', ''))+[' ']\n",
    "        try:\n",
    "            for char in punctuation_marks:\n",
    "                astring = astring.replace(char, '_')\n",
    "        except:\n",
    "            pass\n",
    "        return astring\n",
    "    \n",
    "    def rename_duplicate_dfcols(self, df):\n",
    "        #Rename DF columns if found duplicates (credit to SO\"Lamakaha\")\n",
    "        try:\n",
    "            cols=pd.Series(df.columns)\n",
    "            for dup in df.columns.get_duplicates(): \n",
    "                cols[df.columns.get_loc(dup)]=[dup+'.'+str(d_idx) if d_idx!=0 else dup for d_idx in range(df.columns.get_loc(dup).sum())]\n",
    "                df.columns=cols\n",
    "        except Exception as e:\n",
    "            print(\"Got \", e)\n",
    "            pass\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def save_tosql(self,connection, df_sht, sht, path_to_xlname):\n",
    "        \n",
    "        xlname = path_to_xlname.strip().split('\\\\')[-1]\n",
    "        try:\n",
    "            tablename_insql = str(xlname + '_ONSHEET_' + sht)\n",
    "        except:\n",
    "            tablename_insql = str(xlname)\n",
    "        \n",
    "        #Remove punctuation marks from table name\n",
    "        tablename_insql = Df2db(self.dbname, self.root_path).norm_pctmarks(tablename_insql)\n",
    "        \n",
    "        #Dealing with txt files   \n",
    "        ext = path_to_xlname.split('.')[-1]\n",
    "        if ext == 'txt':\n",
    "            print(path_to_xlname)\n",
    "            txt = open(path_to_xlname).read().splitlines()\n",
    "            df = pd.Series(txt)\n",
    "            df = pd.DataFrame({tablename_insql: df})\n",
    "            #Saving df to sqlite3 db\n",
    "            df.to_sql(tablename_insql, connection, if_exists=\"replace\", index=False)\n",
    "            connection.commit()\n",
    "            print('{} ok'.format(tablename_insql))\n",
    "            \n",
    "        elif ext == 'csv':\n",
    "            \n",
    "            df = pd.read_csv(path_to_xlname)\n",
    "    \n",
    "            #Replacing incompatible with sqlite3 chars with underscores \n",
    "            cols_names = df.columns.values\n",
    "            new_cols_names = []\n",
    "            for col in cols_names:\n",
    "                newcol_name = Df2db(self.dbname, self.root_path).norm_pctmarks(col)\n",
    "                new_cols_names.append(newcol_name)\n",
    "            new_cols_names = [str(n).replace('\\n', '_') for n in new_cols_names]\n",
    "            new_cols_names = [str(n).replace('___', '_') for n in new_cols_names]\n",
    "            new_cols_names = [str(n).replace('__', '_') for n in new_cols_names]\n",
    "            df.columns = new_cols_names\n",
    "            \n",
    "            #Rename duplicate columns from df\n",
    "            df = Df2db(self.dbname, self.root_path).rename_duplicate_dfcols(df)\n",
    "        \n",
    "            #Saving df to sqlite3 db\n",
    "            df.to_sql(tablename_insql, connection, if_exists=\"replace\", index=False)\n",
    "            connection.commit()\n",
    "            print('{} ok'.format(tablename_insql))\n",
    "        \n",
    "        else:\n",
    "            #Replacing incompatible with sqlite3 chars with underscores \n",
    "            cols_names = df_sht.columns.values\n",
    "            new_cols_names = []\n",
    "            for col in cols_names:\n",
    "                newcol_name = Df2db(self.dbname, self.root_path).norm_pctmarks(col)\n",
    "                new_cols_names.append(newcol_name)\n",
    "            new_cols_names = [str(n).replace('\\n', '_') for n in new_cols_names]\n",
    "            new_cols_names = [str(n).replace('___', '_') for n in new_cols_names]\n",
    "            new_cols_names = [str(n).replace('__', '_') for n in new_cols_names]\n",
    "            df_sht.columns = new_cols_names\n",
    "            \n",
    "            #Rename duplicate columns from df\n",
    "            df_sht = Df2db(self.dbname, self.root_path).rename_duplicate_dfcols(df_sht)\n",
    "        \n",
    "            #Saving df to sqlite3 db\n",
    "            df_sht.to_sql(tablename_insql, connection, if_exists=\"replace\", index=False)\n",
    "            connection.commit()\n",
    "            print('{} ok'.format(tablename_insql))\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def xl2sql(self, path_to_xlname):\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        df = pd.ExcelFile(path_to_xlname)\n",
    "        for sht in df.sheet_names:\n",
    "            df_sht = df.parse(sht)\n",
    "            if df_sht.shape == (0,0): \n",
    "                pass\n",
    "            else:\n",
    "                print(\"has\")\n",
    "                Df2db(self.dbname, self.root_path).save_tosql(connection, df_sht,sht,path_to_xlname)\n",
    "                           \n",
    "    def df2sql(self, df, sht='Sheet1'):\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        Df2db(self.dbname, self.root_path).save_tosql(connection, df_sht,sht,path_to_xlname)\n",
    "        \n",
    "    def csv2sql(self, path_to_xlname, df='', sht='Sheet1'):\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        Df2db(self.dbname, self.root_path).save_tosql(connection, df, sht, path_to_xlname)\n",
    "        \n",
    "    def txt2sql(self,path_to_txt, df='', sht=''):\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        Df2db(self.dbname, self.root_path).save_tosql(connection, df, sht, path_to_txt)\n",
    "        \n",
    "    \n",
    "    def df_tosql(self, path_to_xlname, dfname=''):\n",
    "        #Get thru all sheets and if it has data save it to db\n",
    "        filename = path_to_xlname.split('\\\\')[-1]\n",
    "    \n",
    "        if str(type(path_to_xlname)) == \"<class 'pandas.core.frame.DataFrame'>\":\n",
    "            print('df')\n",
    "            Df2db(self.dbname, self.root_path).df2sql(path_to_xlname)\n",
    "        \n",
    "        elif re.search('.xls', filename):\n",
    "            print('.xls')\n",
    "            Df2db(self.dbname, self.root_path).xl2sql(path_to_xlname)\n",
    "                \n",
    "            \n",
    "        elif re.search('.csv', filename):\n",
    "            print('.csv')\n",
    "            Df2db(self.dbname, self.root_path).csv2sql(path_to_xlname)\n",
    "            \n",
    "        elif re.search('.txt', filename):\n",
    "            print('.txt')\n",
    "            Df2db(self.dbname, self.root_path).txt2sql(path_to_xlname)\n",
    "    \n",
    "    \n",
    "            \n",
    "    def getdf_fromdb(self, table_name):\n",
    "        #gets the table from the db\n",
    "        #the table name must have this format excel_xlname_sheet_sheetname\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        query = \"SELECT * FROM {}\".format(table_name)\n",
    "        df = pd.read_sql_query(query, connection)\n",
    "        return df\n",
    "\n",
    "    def show_db_tables(self):\n",
    "        #Shows all tables names from the db\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        all_tb = cursor.fetchall()\n",
    "        #print(all_tb)\n",
    "        all_tb = [x[0] for x in all_tb]\n",
    "        column_name = '{}_TABLES'.format(self.dbname)\n",
    "        df = pd.DataFrame({column_name : all_tb})\n",
    "        try:\n",
    "            df.to_csv(column_name+'.csv', index=False)\n",
    "        except Exception as e:\n",
    "            input('CSV already openned please close it..\\n {}'.format(e))\n",
    "            sys.exit()\n",
    "        print('{} tables in {}\\n'.format(len(all_tb), self.dbname))\n",
    "        return all_tb\n",
    "        \n",
    "        \n",
    "        \n",
    "    def drop_tablefrom_db(self, table_name):\n",
    "        #Using the cursor created in connect_db func executes statement\n",
    "        connection = sqlite3.connect(self.dbname)\n",
    "        cursor = connection.cursor()\n",
    "        query = 'DROP TABLE {};'.format(table_name)\n",
    "        try:\n",
    "            cursor.execute(query)\n",
    "        except Exception as e:\n",
    "            print(\"Table does not exist!\\nPress Enter to exit...\")\n",
    "            input(e)\n",
    "            sys.exit()\n",
    "    \n",
    "    \n",
    "    def getfilespath_from(self):\n",
    "        #Walk thru a start path and return a list of paths to files\n",
    "        allfiles = []\n",
    "        for root, dirs, files in os.walk(self.root_path):\n",
    "            for file in files:\n",
    "                path_tofile = root + '\\\\' + file\n",
    "                allfiles.append(path_tofile)\n",
    "        return allfiles\n",
    "\n",
    "    \n",
    "    def get_dfpaths(self):\n",
    "        #get a list of paths to excel files (.xlsx, .xls, .xlsm, .csv, .txt)\n",
    "        paths_tofiles = Df2db(self.dbname, self.root_path).getfilespath_from()\n",
    "        filtered_extensions = []\n",
    "        files_with_issues = []\n",
    "        for path in paths_tofiles:\n",
    "            file = path.split('\\\\')[-1]\n",
    "            tempfile = \"\".join(list(file)[:2])\n",
    "\n",
    "            if tempfile == \"~$\": # if file open then append to list the path\n",
    "                print('This file {} is open'.format(path))\n",
    "                files_with_issues.append(path)\n",
    "                \n",
    "            elif re.search('.xls', file) or re.search('.csv', file) or re.search('.txt',  file):\n",
    "                filtered_extensions.append(path)   \n",
    "        \n",
    "        #Create a txt file with files that where open\n",
    "        if len(files_with_issues) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            files_with_errors = '\\n'.join(files_with_issues) \n",
    "            error_file = open(\"Files that were open.txt\", 'w')\n",
    "            error_file.write(files_with_errors)\n",
    "            error_file.close()\n",
    "        \n",
    "        return filtered_extensions\n",
    "    \n",
    "    \n",
    "    def dfs_tosql(self):\n",
    "        #Run thru alldfs and save them to db\n",
    "        path_to_dfs = Df2db(self.dbname, self.root_path).get_dfpaths()\n",
    "        print('\\nThere are ',len(path_to_dfs), ' files to be added..\\n\\n')\n",
    "        for df in path_to_dfs:\n",
    "            #print(df)\n",
    "            Df2db(self.dbname, self.root_path).df_tosql(df)\n",
    "        #tab = Df2db(self.dbname, self.root_path).show_db_tables()\n",
    "        \n",
    "#### Instantiating the class\n",
    "todf = Df2db('dxl.db', r'E:\\sqlite3\\files')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#up backup down in work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os, sys, re, string\n",
    "import itertools\n",
    "\n",
    "# \"\"\"\n",
    "# This module can be used to add from a parent folder all the excel files to a sqlite3 database.\n",
    "# The class requires the database name and the path where you have the excel files.\n",
    "\n",
    "# Warning: If it founds an .csv file it will save to database only the first sheet!\n",
    "# Requires pandas module to be installed.\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "class Df2db:\n",
    "    \n",
    "    def __init__(self, dbname, root_path):\n",
    "        self.dbname = dbname\n",
    "        self.root_path = root_path    \n",
    "    \n",
    "    def connect_db(self):\n",
    "        #Connect to a db and if it not exists creates one with the name given\n",
    "        connection = sqlite3.connect(self.dbname)\n",
    "        cursor = connection.cursor()\n",
    "        return connection, cursor\n",
    "    \n",
    "    def close(self):\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        connection.commit()\n",
    "        connection.close()\n",
    "    \n",
    "    def norm_pctmarks(self, astring):\n",
    "        #Removing punctuation marks from the string, necessary for making compatible table names\n",
    "        punctuation_marks = list(str(string.punctuation).replace('_', ''))+[' ']\n",
    "        try:\n",
    "            for char in punctuation_marks:\n",
    "                astring = astring.replace(char, '_')\n",
    "        except:\n",
    "            pass\n",
    "        return astring\n",
    "    \n",
    "    def rename_duplicate_dfcols(self, df):\n",
    "        #Rename DF columns if found duplicates (credit to SO\"Lamakaha\")\n",
    "        try:\n",
    "            cols=pd.Series(df.columns)\n",
    "            for dup in df.columns.get_duplicates(): \n",
    "                cols[df.columns.get_loc(dup)]=[dup+'.'+str(d_idx) if d_idx!=0 else dup for d_idx in range(df.columns.get_loc(dup).sum())]\n",
    "                df.columns=cols\n",
    "        except Exception as e:\n",
    "            print(\"Got \", e)\n",
    "            pass\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def save_tosql(self,connection, df_sht, sht, path_to_xlname):\n",
    "        \n",
    "        xlname = path_to_xlname.strip().split('\\\\')[-1]\n",
    "        try:\n",
    "            tablename_insql = str(xlname + '_ONSHEET_' + sht)\n",
    "        except:\n",
    "            tablename_insql = str(xlname)\n",
    "        \n",
    "        #Remove punctuation marks from table name\n",
    "        tablename_insql = Df2db(self.dbname, self.root_path).norm_pctmarks(tablename_insql)\n",
    "        \n",
    "        #Dealing with txt files   \n",
    "        ext = path_to_xlname.split('.')[-1]\n",
    "        if ext == 'txt':\n",
    "            print(path_to_xlname)\n",
    "            txt = open(path_to_xlname).read().splitlines()\n",
    "            df = pd.Series(txt)\n",
    "            df = pd.DataFrame({tablename_insql: df})\n",
    "            #Saving df to sqlite3 db\n",
    "            df.to_sql(tablename_insql, connection, if_exists=\"replace\", index=False)\n",
    "            connection.commit()\n",
    "            print('{} ok'.format(tablename_insql))\n",
    "            \n",
    "        elif ext == 'csv':\n",
    "            \n",
    "            df = pd.read_csv(path_to_xlname)\n",
    "    \n",
    "            #Replacing incompatible with sqlite3 chars with underscores \n",
    "            cols_names = df.columns.values\n",
    "            new_cols_names = []\n",
    "            for col in cols_names:\n",
    "                newcol_name = Df2db(self.dbname, self.root_path).norm_pctmarks(col)\n",
    "                new_cols_names.append(newcol_name)\n",
    "            new_cols_names = [str(n).replace('\\n', '_') for n in new_cols_names]\n",
    "            new_cols_names = [str(n).replace('___', '_') for n in new_cols_names]\n",
    "            new_cols_names = [str(n).replace('__', '_') for n in new_cols_names]\n",
    "            df.columns = new_cols_names\n",
    "            \n",
    "            #Rename duplicate columns from df\n",
    "            df = Df2db(self.dbname, self.root_path).rename_duplicate_dfcols(df)\n",
    "        \n",
    "            #Saving df to sqlite3 db\n",
    "            df.to_sql(tablename_insql, connection, if_exists=\"replace\", index=False)\n",
    "            connection.commit()\n",
    "            print('{} ok'.format(tablename_insql))\n",
    "        \n",
    "        else:\n",
    "            #Replacing incompatible with sqlite3 chars with underscores \n",
    "            cols_names = df_sht.columns.values\n",
    "            new_cols_names = []\n",
    "            for col in cols_names:\n",
    "                newcol_name = Df2db(self.dbname, self.root_path).norm_pctmarks(col)\n",
    "                new_cols_names.append(newcol_name)\n",
    "            new_cols_names = [str(n).replace('\\n', '_') for n in new_cols_names]\n",
    "            new_cols_names = [str(n).replace('___', '_') for n in new_cols_names]\n",
    "            new_cols_names = [str(n).replace('__', '_') for n in new_cols_names]\n",
    "            df_sht.columns = new_cols_names\n",
    "            \n",
    "            #Rename duplicate columns from df\n",
    "            df_sht = Df2db(self.dbname, self.root_path).rename_duplicate_dfcols(df_sht)\n",
    "        \n",
    "            #Saving df to sqlite3 db\n",
    "            df_sht.to_sql(tablename_insql, connection, if_exists=\"replace\", index=False)\n",
    "            connection.commit()\n",
    "            print('{} ok'.format(tablename_insql))\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def xl2sql(self, path_to_xlname):\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        df = pd.ExcelFile(path_to_xlname)\n",
    "        for sht in df.sheet_names:\n",
    "            df_sht = df.parse(sht)\n",
    "            if df_sht.shape == (0,0): \n",
    "                pass\n",
    "            else:\n",
    "                print(\"has\")\n",
    "                Df2db(self.dbname, self.root_path).save_tosql(connection, df_sht,sht,path_to_xlname)\n",
    "                           \n",
    "    def df2sql(self, df, dfname):\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        print('conn si cursor ok\\n', type(df), dfname)\n",
    "        input()\n",
    "        #Saving df to sqlite3 db\n",
    "        df.to_sql(dfname, connection, if_exists=\"replace\", index=False)\n",
    "        connection.commit()\n",
    "        print('{} ok'.format(dfname))\n",
    "        #Df2db(self.dbname, self.root_path).save_tosql(connection, df_sht,sht,path_to_xlname)\n",
    "        \n",
    "    def csv2sql(self, path_to_xlname, df='', sht='Sheet1'):\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        Df2db(self.dbname, self.root_path).save_tosql(connection, df, sht, path_to_xlname)\n",
    "        \n",
    "    def txt2sql(self,path_to_txt, df='', sht=''):\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        Df2db(self.dbname, self.root_path).save_tosql(connection, df, sht, path_to_txt)\n",
    "        \n",
    "    \n",
    "    def df_tosql(self, path_to_xlname, dfname=''):\n",
    "        #Get thru all sheets and if it has data save it to db\n",
    "        try:\n",
    "            filename = path_to_xlname.split('\\\\')[-1]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        input('trecut de trypass')\n",
    "    \n",
    "        if str(type(path_to_xlname)) == \"<class 'pandas.core.frame.DataFrame'>\":\n",
    "\n",
    "            input('recunoscut ca df')\n",
    "            \n",
    "            Df2db(self.dbname, self.root_path).df2sql(path_to_xlname, dfname)\n",
    "        \n",
    "        elif re.search('.xls', filename):\n",
    "            print('.xls')\n",
    "            Df2db(self.dbname, self.root_path).xl2sql(path_to_xlname)\n",
    "                \n",
    "            \n",
    "        elif re.search('.csv', filename):\n",
    "            print('.csv')\n",
    "            Df2db(self.dbname, self.root_path).csv2sql(path_to_xlname)\n",
    "            \n",
    "        elif re.search('.txt', filename):\n",
    "            print('.txt')\n",
    "            Df2db(self.dbname, self.root_path).txt2sql(path_to_xlname)\n",
    "    \n",
    "    \n",
    "            \n",
    "    def getdf_fromdb(self, table_name):\n",
    "        #gets the table from the db\n",
    "        #the table name must have this format excel_xlname_sheet_sheetname\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        query = \"SELECT * FROM {}\".format(table_name)\n",
    "        df = pd.read_sql_query(query, connection)\n",
    "        return df\n",
    "\n",
    "    def show_db_tables(self):\n",
    "        #Shows all tables names from the db\n",
    "        connection, cursor = Df2db(self.dbname, self.root_path).connect_db()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        all_tb = cursor.fetchall()\n",
    "        all_tb = [x[0] for x in all_tb] # from [(table1, ) etc] makes [table1, etc]\n",
    "        column_name = '{}_TABLES'.format(self.dbname)\n",
    "        df = pd.DataFrame({column_name : all_tb})\n",
    "        try:\n",
    "            df.to_csv(column_name+'.csv', index=False)\n",
    "        except Exception as e:\n",
    "            input('CSV already openned please close it..\\n {}'.format(e))\n",
    "            sys.exit()\n",
    "        print('{} tables in {}\\n'.format(len(all_tb), self.dbname))\n",
    "        return all_tb\n",
    "        \n",
    "        \n",
    "        \n",
    "    def drop_tablefrom_db(self, table_name):\n",
    "        #Using the cursor created in connect_db func executes statement\n",
    "        connection = sqlite3.connect(self.dbname)\n",
    "        cursor = connection.cursor()\n",
    "        query = 'DROP TABLE {};'.format(table_name)\n",
    "        try:\n",
    "            cursor.execute(query)\n",
    "        except Exception as e:\n",
    "            print(\"Table does not exist!\\nPress Enter to exit...\")\n",
    "            input(e)\n",
    "            sys.exit()\n",
    "    \n",
    "    \n",
    "    def getfilespath_from(self):\n",
    "        #Walk thru a start path and return a list of paths to files\n",
    "        allfiles = []\n",
    "        for root, dirs, files in os.walk(self.root_path):\n",
    "            for file in files:\n",
    "                path_tofile = root + '\\\\' + file\n",
    "                allfiles.append(path_tofile)\n",
    "        return allfiles\n",
    "\n",
    "    \n",
    "    def get_dfpaths(self):\n",
    "        #get a list of paths to excel files (.xlsx, .xls, .xlsm, .csv, .txt)\n",
    "        paths_tofiles = Df2db(self.dbname, self.root_path).getfilespath_from()\n",
    "        filtered_extensions = []\n",
    "        files_with_issues = []\n",
    "        for path in paths_tofiles:\n",
    "            file = path.split('\\\\')[-1]\n",
    "            tempfile = \"\".join(list(file)[:2])\n",
    "\n",
    "            if tempfile == \"~$\": # if file open then append to list the path\n",
    "                print('This file {} is open'.format(path))\n",
    "                files_with_issues.append(path)\n",
    "                \n",
    "            elif re.search('.xls', file) or re.search('.csv', file) or re.search('.txt',  file):\n",
    "                filtered_extensions.append(path)   \n",
    "        \n",
    "        #Create a txt file with files that where open\n",
    "        if len(files_with_issues) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            files_with_errors = '\\n'.join(files_with_issues) \n",
    "            error_file = open(\"Files that were open.txt\", 'w')\n",
    "            error_file.write(files_with_errors)\n",
    "            error_file.close()\n",
    "        \n",
    "        return filtered_extensions\n",
    "    \n",
    "    \n",
    "    def dfs_tosql(self):\n",
    "        #Run thru alldfs and save them to db\n",
    "        path_to_dfs = Df2db(self.dbname, self.root_path).get_dfpaths()\n",
    "        print('\\nThere are ',len(path_to_dfs), ' files to be added..\\n\\n')\n",
    "        for df in path_to_dfs:\n",
    "            #print(df)\n",
    "            Df2db(self.dbname, self.root_path).df_tosql(df)\n",
    "        #tab = Df2db(self.dbname, self.root_path).show_db_tables()\n",
    "        \n",
    "#### Instantiating the class\n",
    "todf = Df2db('mydata.db', r'E:\\sqlite3')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orase = pd.read_csv('orase.csv')\n",
    "jud_loc = orase[['JUDET', 'LOCALITATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trecut de trypass\n",
      "recunoscut ca df\n",
      "conn si cursor ok\n",
      " <class 'pandas.core.frame.DataFrame'> judloc\n",
      "\n",
      "judloc ok\n"
     ]
    }
   ],
   "source": [
    "todf.df_tosql(jud_loc, 'judloc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tables in mydata.db\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['judloc']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todf.show_db_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JUDET</th>\n",
       "      <th>LOCALITATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Alba Iulia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Barabant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Micesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Oarda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Paclisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Ciugud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Drambar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Limba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Hapria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Seusa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Teleac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Abrud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Abrud-Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Gura Cornei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Soharu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Aiud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Aiudul de Sus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Gambas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Magina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Pagida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Ciumbrud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Garbova de Jos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Garbova de Sus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Garbovita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Sancrai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Tifra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Blaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Deleni-Obarsie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Flitesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Alba</td>\n",
       "      <td>Izvoarele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13719</th>\n",
       "      <td>Vrancea</td>\n",
       "      <td>Botarlau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13720</th>\n",
       "      <td>Vrancea</td>\n",
       "      <td>Hangulesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <td>Vrancea</td>\n",
       "      <td>Maluri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13722</th>\n",
       "      <td>Vrancea</td>\n",
       "      <td>Vadu Rosca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13723</th>\n",
       "      <td>Bucuresti</td>\n",
       "      <td>Municipiul Bucuresti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13724</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Bragadiru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13725</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Chiajna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13726</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Dudu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13727</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Rosu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13728</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Chitila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13729</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Rudeni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13730</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Dobroesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13731</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Fundeni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13732</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Glina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13733</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Catelu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13734</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Manolache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13735</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Jilava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13736</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Magurele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13737</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Alunisu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13738</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Dumitrana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13739</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Pruni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13740</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Varteju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13741</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Mogosoaia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13742</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Otopeni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13743</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Odaile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13744</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Pantelimon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13745</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Popesti Leordeni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13746</th>\n",
       "      <td>Ilfov</td>\n",
       "      <td>Voluntari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13747</th>\n",
       "      <td>Maramures</td>\n",
       "      <td>Salta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13748</th>\n",
       "      <td>Giurgiu</td>\n",
       "      <td>Comasca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13749 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           JUDET            LOCALITATE\n",
       "0           Alba            Alba Iulia\n",
       "1           Alba              Barabant\n",
       "2           Alba               Micesti\n",
       "3           Alba                 Oarda\n",
       "4           Alba               Paclisa\n",
       "5           Alba                Ciugud\n",
       "6           Alba               Drambar\n",
       "7           Alba                 Limba\n",
       "8           Alba                Hapria\n",
       "9           Alba                 Seusa\n",
       "10          Alba                Teleac\n",
       "11          Alba                 Abrud\n",
       "12          Alba             Abrud-Sat\n",
       "13          Alba           Gura Cornei\n",
       "14          Alba                Soharu\n",
       "15          Alba                  Aiud\n",
       "16          Alba         Aiudul de Sus\n",
       "17          Alba                Gambas\n",
       "18          Alba                Magina\n",
       "19          Alba                Pagida\n",
       "20          Alba              Ciumbrud\n",
       "21          Alba        Garbova de Jos\n",
       "22          Alba        Garbova de Sus\n",
       "23          Alba             Garbovita\n",
       "24          Alba               Sancrai\n",
       "25          Alba                 Tifra\n",
       "26          Alba                  Blaj\n",
       "27          Alba        Deleni-Obarsie\n",
       "28          Alba              Flitesti\n",
       "29          Alba             Izvoarele\n",
       "...          ...                   ...\n",
       "13719    Vrancea              Botarlau\n",
       "13720    Vrancea            Hangulesti\n",
       "13721    Vrancea                Maluri\n",
       "13722    Vrancea            Vadu Rosca\n",
       "13723  Bucuresti  Municipiul Bucuresti\n",
       "13724      Ilfov             Bragadiru\n",
       "13725      Ilfov               Chiajna\n",
       "13726      Ilfov                  Dudu\n",
       "13727      Ilfov                  Rosu\n",
       "13728      Ilfov               Chitila\n",
       "13729      Ilfov                Rudeni\n",
       "13730      Ilfov             Dobroesti\n",
       "13731      Ilfov               Fundeni\n",
       "13732      Ilfov                 Glina\n",
       "13733      Ilfov                Catelu\n",
       "13734      Ilfov             Manolache\n",
       "13735      Ilfov                Jilava\n",
       "13736      Ilfov              Magurele\n",
       "13737      Ilfov               Alunisu\n",
       "13738      Ilfov             Dumitrana\n",
       "13739      Ilfov                 Pruni\n",
       "13740      Ilfov               Varteju\n",
       "13741      Ilfov             Mogosoaia\n",
       "13742      Ilfov               Otopeni\n",
       "13743      Ilfov                Odaile\n",
       "13744      Ilfov            Pantelimon\n",
       "13745      Ilfov      Popesti Leordeni\n",
       "13746      Ilfov             Voluntari\n",
       "13747  Maramures                 Salta\n",
       "13748    Giurgiu               Comasca\n",
       "\n",
       "[13749 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todf.getdf_fromdb(\"judloc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "todf.drop_tablefrom_db(\"orase_csv_ONSHEET_Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tables in mydata.db\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['judloc']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todf.show_db_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Import class Df2db from df2db module\n",
    "from df2db import Df2db\n",
    "\n",
    "#Instantiate with the database name and the path where you got excel files\n",
    "todf = Df2db('dbname.db', r'D:\\alot_of_xlfiles')\n",
    "\n",
    "#Call dfs_tosql function to search in the path you give for excel files \n",
    "#and save them to the database with the name given\n",
    "todf.dfs_tosql()\n",
    "\n",
    "#Show tables from the database\n",
    "todf.show_db_tables()\n",
    "\n",
    "#Get a table from the database as a dataframe object\n",
    "#in order to use it in pandas for manipulation\n",
    "todf.getdf_fromdb(\"EXCEL_xl4_xlsx_SHEET_Sheet1\")\n",
    "\n",
    "#Delete a table from the database\n",
    "todf.drop_tablefrom_db(\"EXCEL_xl4_xlsx_SHEET_Sheet1\")\n",
    "\n",
    "#Show tables from db, now you see one it's gone\n",
    "todf.show_db_tables()\n",
    "\n",
    "#Close the connection when you are done.\n",
    "todf.close()\n",
    "\n",
    "#Instantiate with the database name and the path where you got excel files\n",
    "todf = Df2db('dbname.db', r'D:\\alot_of_xlfiles')\n",
    "\n",
    "#Make a dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dates = pd.date_range('20130101', periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "\n",
    "#Save it to sql, you must give the df and a name for the df\n",
    "todf.df_tosql(df, 'test')\n",
    "\n",
    "#Show current tables from db \n",
    "todf.show_db_tables()\n",
    "#Close when you are done\n",
    "todf.close()\n",
    "\n",
    "#Each table saved in database will have this form\n",
    "tablname = \"EXCEL_test_xlsx_SHEET_Sheet1\"\n",
    "tablname.split('_')\n",
    "\n",
    "\n",
    "'EXCEL' - all tables in db will start with this prefix\n",
    "'test' - the name if the excel or df \n",
    "'xlsx' - the extension of the file\n",
    "'SHEET' - the next folowing this will be the Sheet name of the excel\n",
    "That's because it looks in the workbook in all sheets for tables and saves the sheet name also\n",
    "'Sheet1' - The sheet where the table was found\n",
    "\n",
    "If the excel or df has punctuation marks or spaces those will be replaced with underscore \"_\"\n",
    "This replace is done in order to be compatible with sqlite3 database\n",
    "Also, if the column names contains spaces those will be replaced with \"_\"\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
